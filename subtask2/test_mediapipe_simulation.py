#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å®é™…çš„MediaPipeæ£€æµ‹ç»“æœæ¨¡æ‹Ÿ
"""

import cv2
import numpy as np
from feature_extractor import FeatureExtractor

def simulate_mediapipe_results():
    """æ¨¡æ‹ŸMediaPipeçš„æ£€æµ‹ç»“æœ"""

    print("ğŸ”¬ æ¨¡æ‹ŸMediaPipeæ£€æµ‹ç»“æœ...")

    # åˆ›å»ºæ¨¡æ‹Ÿçš„æ£€æµ‹ç»“æœç±»
    class MockPoseResults:
        def __init__(self, has_pose=True):
            self.pose_landmarks = None
            if has_pose:
                # æ¨¡æ‹Ÿ33ä¸ªèº«ä½“å…³é”®ç‚¹
                self.pose_landmarks = MockLandmarks(33)

    class MockHandResults:
        def __init__(self, num_hands=0):
            self.multi_hand_landmarks = None
            if num_hands > 0:
                self.multi_hand_landmarks = []
                for _ in range(num_hands):
                    self.multi_hand_landmarks.append(MockLandmarks(21))

    class MockLandmarks:
        def __init__(self, num_points):
            self.landmark = []
            for i in range(num_points):
                landmark = MockLandmark()
                landmark.x = np.random.rand() * 0.2 + 0.4  # 0.4-0.6èŒƒå›´
                landmark.y = np.random.rand() * 0.2 + 0.3  # 0.3-0.5èŒƒå›´
                landmark.z = np.random.rand() * 0.1 - 0.05  # -0.05-0.05èŒƒå›´
                self.landmark.append(landmark)

    class MockLandmark:
        def __init__(self):
            self.x = 0.0
            self.y = 0.0
            self.z = 0.0

    # æµ‹è¯•ä¸åŒçš„åœºæ™¯
    scenarios = [
        ("åŒæ‰‹ä¸åŠ¨", MockPoseResults(True), MockHandResults(0)),
        ("å•æ‰‹æ‰‹åŠ¿", MockPoseResults(True), MockHandResults(1)),
        ("åŒæ‰‹æ‰‹åŠ¿", MockPoseResults(True), MockHandResults(2)),
        ("æ— å§¿åŠ¿æ— æ‰‹åŠ¿", MockPoseResults(False), MockHandResults(0)),
    ]

    try:
        extractor = FeatureExtractor()

        for scenario_name, pose_results, hand_results in scenarios:
            print(f"\nğŸ“‹ æµ‹è¯•åœºæ™¯: {scenario_name}")

            # åˆ›å»ºä¸€ä¸ªæµ‹è¯•å¸§
            frame = np.zeros((480, 640, 3), dtype=np.uint8)

            # æ¨¡æ‹Ÿç‰¹å¾æå–
            keypoints, _, _ = extractor._extract_old_api(frame)

            # æ£€æŸ¥æ‰‹åŠ¿æ£€æµ‹é€»è¾‘
            has_hands = hand_results.multi_hand_landmarks is not None and len(hand_results.multi_hand_landmarks) > 0
            has_pose = pose_results.pose_landmarks is not None

            # è®¡ç®—æ‰‹åŠ¿æ£€æµ‹æ¯”ä¾‹ï¼ˆæ¨¡æ‹Ÿæœ€è¿‘5å¸§ï¼‰
            hand_detection_ratio = 1.0 if has_hands else 0.0
            gesture_detected = hand_detection_ratio > 0.3

            print(f"   æ£€æµ‹åˆ°å§¿åŠ¿: {has_pose}")
            print(f"   æ£€æµ‹åˆ°æ‰‹åŠ¿: {has_hands}")
            print(f"   æ‰‹åŠ¿æ£€æµ‹æ¯”ä¾‹: {hand_detection_ratio:.3f}")
            print(f"   åˆ¤æ–­ä¸ºæ‰‹åŠ¿: {gesture_detected}")

            # æ£€æŸ¥å…³é”®ç‚¹æ•°æ®
            pose_keypoints = keypoints[:99]  # å‰99ä¸ªæ˜¯å§¿åŠ¿
            hand_keypoints = keypoints[99:]  # å126ä¸ªæ˜¯æ‰‹åŠ¿

            pose_nonzero = np.mean(pose_keypoints != 0)
            hand_nonzero = np.mean(hand_keypoints != 0)

            print(f"   å§¿åŠ¿å…³é”®ç‚¹éé›¶æ¯”ä¾‹: {pose_nonzero:.3f}")
            print(f"   æ‰‹åŠ¿å…³é”®ç‚¹éé›¶æ¯”ä¾‹: {hand_nonzero:.3f}")

        extractor.close()

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

    print("\nâœ… æ¨¡æ‹Ÿæµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    simulate_mediapipe_results()